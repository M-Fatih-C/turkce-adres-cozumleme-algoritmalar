{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyP+sQYvyxJhQbSxKCAC2CwV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Google Colab'da çalıştırmak için:\n","!pip install pandas numpy fuzzywuzzy scikit-learn folium geopy geopandas\n","\n","# Dosyaları yükle\n","# train.csv, test.csv dosyalarını upload et\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2l7SMMzsTRJW","executionInfo":{"status":"ok","timestamp":1756064383314,"user_tz":-180,"elapsed":7414,"user":{"displayName":"Muhammet Fatih Çetintas","userId":"02746250817952515216"}},"outputId":"390d3c40-c183-43f6-d5ba-68e4f2996efa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Collecting fuzzywuzzy\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: folium in /usr/local/lib/python3.12/dist-packages (0.20.0)\n","Requirement already satisfied: geopy in /usr/local/lib/python3.12/dist-packages (2.4.1)\n","Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from folium) (0.8.1)\n","Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from folium) (3.1.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from folium) (2.32.4)\n","Requirement already satisfied: xyzservices in /usr/local/lib/python3.12/dist-packages (from folium) (2025.4.0)\n","Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.12/dist-packages (from geopy) (2.0)\n","Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.11.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas) (25.0)\n","Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (3.7.2)\n","Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.1.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from pyogrio>=0.7.2->geopandas) (2025.8.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (2.5.0)\n","Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0\n"]}]},{"cell_type":"code","source":["!pip install unidecode fuzzywuzzy folium geopy geopandas -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axCZROKMn3QZ","executionInfo":{"status":"ok","timestamp":1756064878305,"user_tz":-180,"elapsed":5123,"user":{"displayName":"Muhammet Fatih Çetintas","userId":"02746250817952515216"}},"outputId":"329ab5e8-5373-4612-855e-fcd40105d72e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"ha_WiGhiWZtl"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KIXknSgTTNqT","executionInfo":{"status":"ok","timestamp":1756068070672,"user_tz":-180,"elapsed":177040,"user":{"displayName":"Muhammet Fatih Çetintas","userId":"02746250817952515216"}},"outputId":"d5a07494-6ec7-4de5-f0ae-0932b4612e66"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","TURKISH ADDRESS PROCESSOR - COMPREHENSIVE TEST\n","================================================================================\n","\n","1. BASIC PREPROCESSING TEST\n","--------------------------------------------------\n","Original:  Çankaya Mah. Atatürk Bulv. No:125/A D:3 K:2 Ankara\n","Processed: cankaya mahallesi ataturk bulvar numara 125a daire 3 kat 2 ankara\n","\n","Original:  Kadıköy İskele Cd. No:10/B İstanbul\n","Processed: kadikoy iskele caddesi numara 10b istanbul\n","\n","Original:  Narlıdere Mah. Mithatpaşa Cd. No:15/A D:3 K:2 İzmir\n","Processed: narlidere mahallesi mithatpasa caddesi numara 15a daire 3 kat 2 izmir\n","\n","Original:  Fatih mah menderes bul No;25D:4\n","Processed: fatih mahallesi menderes bulvar numara 25d 4\n","\n","Original:  YENİ MAH. ESKİ SOK. APT. NO:5 DAİRE:3 KAT:2\n","Processed: yeni mahallesi eski sokak apartmani numara 5 daire 3 kat 2\n","\n","\n","2. ADDRESS STANDARDIZATION TEST\n","--------------------------------------------------\n","Original:     Çankaya Mah. Atatürk Bulv. No:125/A D:3 K:2 Ankara\n","Standardized: cankaya mahallesi cankaya mahallesi ataturk numara 125a kat 2 daire 3 cankaya ankara\n","\n","Original:     Kadıköy İskele Cd. No:10/B İstanbul\n","Standardized: kadikoy iskele numara 10b kadikoy istanbul\n","\n","Original:     Narlıdere Mah. Mithatpaşa Cd. No:15/A D:3 K:2 İzmir\n","Standardized: narlidere mahallesi narlidere mahallesi mithatpasa numara 15a kat 2 daire 3 narlidere izmir\n","\n","Original:     Fatih mah menderes bul No;25D:4\n","Standardized: fatih mahallesi fatih mahallesi menderes numara 25d daire 4\n","\n","Original:     YENİ MAH. ESKİ SOK. APT. NO:5 DAİRE:3 KAT:2\n","Standardized: yeni mahallesi yeni mahallesi eski numara 5 kat 2 daire 3\n","\n","\n","3. COMPONENT EXTRACTION TEST\n","--------------------------------------------------\n","Address: Çankaya Mah. Atatürk Bulv. No:125/A D:3 K:2 Ankara\n","Components:\n","  floor: 2\n","  apartment: 3\n","  building_no: 125a\n","  district: cankaya\n","  street: cankaya mahallesi ataturk\n","  city: ankara\n","  district_name: cankaya\n","\n","Address: Kadıköy İskele Cd. No:10/B İstanbul\n","Components:\n","  building_no: 10b\n","  street: kadikoy iskele\n","  village: kadi\n","  city: istanbul\n","  district_name: kadikoy\n","\n","Address: Narlıdere Mah. Mithatpaşa Cd. No:15/A D:3 K:2 İzmir\n","Components:\n","  floor: 2\n","  apartment: 3\n","  building_no: 15a\n","  district: narlidere\n","  street: narlidere mahallesi mithatpasa\n","  city: izmir\n","  district_name: narlidere\n","\n","\n","4. ADDRESS HIERARCHY TEST\n","--------------------------------------------------\n","Address: Çankaya Mah. Atatürk Bulv. No:125/A D:3 K:2 Ankara\n","Hierarchy:\n","  country: turkiye\n","  city: ankara\n","  district: cankaya\n","  neighborhood: cankaya\n","  street: cankaya mahallesi ataturk\n","  building: 125a\n","  floor: 2\n","  apartment: 3\n","\n","Address: Kadıköy İskele Cd. No:10/B İstanbul\n","Hierarchy:\n","  country: turkiye\n","  city: istanbul\n","  district: kadikoy\n","  street: kadikoy iskele\n","  building: 10b\n","\n","Address: Narlıdere Mah. Mithatpaşa Cd. No:15/A D:3 K:2 İzmir\n","Hierarchy:\n","  country: turkiye\n","  city: izmir\n","  district: narlidere\n","  neighborhood: narlidere\n","  street: narlidere mahallesi mithatpasa\n","  building: 15a\n","  floor: 2\n","  apartment: 3\n","\n","\n","5. ADDRESS SIMILARITY TEST\n","--------------------------------------------------\n","Address 1: Çankaya Mah. Atatürk Bulv. No:125/A D:3 K:2 Ankara\n","Address 2: Çankaya Mahallesi Atatürk Bulvarı 125A Daire 3 Ankara\n","Match: NO (Score: 79.63%)\n","Component similarities:\n","  apartment: 100.00%\n","  building_no: 0.00%\n","  street: 100.00%\n","  district: 100.00%\n","  city: 100.00%\n","  floor: 0.00%\n","  district_name: 100.00%\n","\n","Address 1: Kadıköy İskele Cd. No:10/B İstanbul\n","Address 2: kadikoy iskele caddesi no 10B istanbul\n","Match: NO (Score: 65.68%)\n","Component similarities:\n","  building_no: 100.00%\n","  street: 100.00%\n","  village: 100.00%\n","  city: 100.00%\n","  district_name: 100.00%\n","\n","Address 1: Beşiktaş Barbaros Bulvarı No:145 Kat:3 Daire:12 İSTANBUL\n","Address 2: Beşiktaş Barbaros Bulv. No:145 D:12 K:3 İstanbul\n","Match: YES (Score: 97.00%)\n","Component similarities:\n","  apartment: 100.00%\n","  building_no: 100.00%\n","  street: 100.00%\n","  city: 100.00%\n","  floor: 100.00%\n","  district_name: 100.00%\n","\n","Address 1: Atatürk Mah. İnönü Sok. No:25 Ankara\n","Address 2: atatürk mahallesi inönü sokak 25 ankara\n","Match: NO (Score: 74.80%)\n","Component similarities:\n","  building_no: 0.00%\n","  street: 100.00%\n","  district: 100.00%\n","  city: 100.00%\n","  floor: 0.00%\n","\n","\n","6. FEATURE EXTRACTION TEST\n","--------------------------------------------------\n","Address: Çankaya Mah. Atatürk Bulv. No:125/A D:3 K:2 Ankara\n","Features:\n","  Length: 65\n","  Words: 11\n","  Components: 7\n","  Valid: True\n","  Has Number: True\n","\n","Address: Kadıköy İskele Cd. No:10/B İstanbul\n","Features:\n","  Length: 42\n","  Words: 6\n","  Components: 5\n","  Valid: True\n","  Has Number: True\n","\n","Address: Narlıdere Mah. Mithatpaşa Cd. No:15/A D:3 K:2 İzmir\n","Features:\n","  Length: 69\n","  Words: 11\n","  Components: 7\n","  Valid: True\n","  Has Number: True\n","\n","\n","7. BATCH PROCESSING TEST\n","--------------------------------------------------\n","Processing 13 addresses...\n","Extracting address features...\n","Detecting fuzzy duplicates...\n","\n","Preprocessing Statistics:\n","Total addresses: 13\n","Valid addresses: 13\n","Exact duplicates: 0\n","Standardized duplicates: 0\n","Fuzzy duplicates: 0\n","Processed 13 addresses\n","\n","DataFrame columns:\n","['address', 'processed_address', 'standardized_address', 'feat_length', 'feat_word_count', 'feat_component_count', 'feat_has_number', 'feat_is_valid', 'feat_has_postal_code', 'feat_has_building_no', 'feat_has_apartment', 'feat_has_floor', 'feat_has_street', 'feat_has_district', 'is_duplicate_exact', 'is_duplicate_standard', 'is_duplicate_fuzzy', 'is_valid_address']\n","\n","Sample results:\n","                                               address                                                      processed_address  feat_component_count  is_valid_address\n","0   Çankaya Mah. Atatürk Bulv. No:125/A D:3 K:2 Ankara      cankaya mahallesi ataturk bulvar numara 125a daire 3 kat 2 ankara                     7              True\n","1                  Kadıköy İskele Cd. No:10/B İstanbul                             kadikoy iskele caddesi numara 10b istanbul                     5              True\n","2  Narlıdere Mah. Mithatpaşa Cd. No:15/A D:3 K:2 İzmir  narlidere mahallesi mithatpasa caddesi numara 15a daire 3 kat 2 izmir                     7              True\n","\n","8. DUPLICATE DETECTION TEST\n","--------------------------------------------------\n","Processing 5 addresses...\n","Extracting address features...\n","Detecting fuzzy duplicates...\n","\n","Preprocessing Statistics:\n","Total addresses: 5\n","Valid addresses: 5\n","Exact duplicates: 3\n","Standardized duplicates: 3\n","Fuzzy duplicates: 3\n","Duplicate analysis:\n","Kadıköy İskele Cad. No:10 İstanbul\n","  Exact duplicate: False\n","  Standard duplicate: False\n","  Fuzzy duplicate: False\n","kadikoy iskele caddesi no 10 istanbul\n","  Exact duplicate: True\n","  Standard duplicate: True\n","  Fuzzy duplicate: True\n","KADIKOY ISKELE CAD NO:10 ISTANBUL\n","  Exact duplicate: True\n","  Standard duplicate: True\n","  Fuzzy duplicate: True\n","Bakırköy İstasyon Cad. No:22 İstanbul\n","  Exact duplicate: False\n","  Standard duplicate: False\n","  Fuzzy duplicate: False\n","bakirkoy istasyon caddesi no 22 istanbul\n","  Exact duplicate: True\n","  Standard duplicate: True\n","  Fuzzy duplicate: True\n","\n","9. ADDRESS VALIDATION TEST\n","--------------------------------------------------\n","Address: 'Çankaya Mah. Atatürk Bulv. No:125 Ankara' -> Valid: True\n","Address: 'İstanbul' -> Valid: False\n","Address: '-----' -> Valid: False\n","Address: '12345' -> Valid: False\n","Address: 'Ankara Çankaya' -> Valid: True\n","Address: '' -> Valid: False\n","\n","10. ADDRESS QUALITY REPORT\n","--------------------------------------------------\n","total_addresses: 13\n","\n","11. NUMBER NORMALIZATION EDGE CASES\n","--------------------------------------------------\n","Input:  No:25D:4\n","Output: numara 25 daire 4\n","Input:  No: 5\n","Output: numara 5\n","Input:  No.25/A\n","Output: numara 25a\n","Input:  25/B\n","Output: 25b\n","Input:  D: 5\n","Output: daire 5\n","Input:  Daire 5\n","Output: daire 5\n","Input:  K: 2\n","Output: kat 2\n","Input:  Kat: 2\n","Output: kat: 2\n","Input:  birinci kat\n","Output: 1 kat\n","Input:  ikinci sokak\n","Output: 2 sokak\n","Input:  üçüncü cadde\n","Output: üçüncü cadde\n","\n","12. PERFORMANCE TEST\n","--------------------------------------------------\n","Processing 1300 addresses...\n","\n","Preprocessing Statistics:\n","Total addresses: 1300\n","Valid addresses: 1300\n","Processed 1300 addresses in 29.11 seconds\n","Speed: 45 addresses/second\n","\n","================================================================================\n","ALL TESTS COMPLETED SUCCESSFULLY!\n","================================================================================\n","processed_addresses: 13\n","\n","11. NUMBER NORMALIZATION EDGE CASES\n","--------------------------------------------------\n","Input:  No:25D:4\n","Output: numara 25 daire 4\n","Input:  No: 5\n","Output: numara 5\n","Input:  No.25/A\n","Output: numara 25a\n","Input:  25/B\n","Output: 25b\n","Input:  D: 5\n","Output: daire 5\n","Input:  Daire 5\n","Output: daire 5\n","Input:  K: 2\n","Output: kat 2\n","Input:  Kat: 2\n","Output: kat: 2\n","Input:  birinci kat\n","Output: 1 kat\n","Input:  ikinci sokak\n","Output: 2 sokak\n","Input:  üçüncü cadde\n","Output: üçüncü cadde\n","\n","12. PERFORMANCE TEST\n","--------------------------------------------------\n","Processing 1300 addresses...\n","\n","Preprocessing Statistics:\n","Total addresses: 1300\n","Valid addresses: 1300\n","Processed 1300 addresses in 29.12 seconds\n","Speed: 45 addresses/second\n","\n","================================================================================\n","ALL TESTS COMPLETED SUCCESSFULLY!\n","================================================================================\n","valid_addresses: 13\n","\n","11. NUMBER NORMALIZATION EDGE CASES\n","--------------------------------------------------\n","Input:  No:25D:4\n","Output: numara 25 daire 4\n","Input:  No: 5\n","Output: numara 5\n","Input:  No.25/A\n","Output: numara 25a\n","Input:  25/B\n","Output: 25b\n","Input:  D: 5\n","Output: daire 5\n","Input:  Daire 5\n","Output: daire 5\n","Input:  K: 2\n","Output: kat 2\n","Input:  Kat: 2\n","Output: kat: 2\n","Input:  birinci kat\n","Output: 1 kat\n","Input:  ikinci sokak\n","Output: 2 sokak\n","Input:  üçüncü cadde\n","Output: üçüncü cadde\n","\n","12. PERFORMANCE TEST\n","--------------------------------------------------\n","Processing 1300 addresses...\n","\n","Preprocessing Statistics:\n","Total addresses: 1300\n","Valid addresses: 1300\n","Processed 1300 addresses in 29.04 seconds\n","Speed: 45 addresses/second\n","\n","================================================================================\n","ALL TESTS COMPLETED SUCCESSFULLY!\n","================================================================================\n","statistics:\n","  avg_length: 54.46153846153846\n","  min_length: 36\n","  max_length: 69\n","  avg_words: 8.384615384615385\n","  min_words: 6\n","  max_words: 11\n","\n","11. NUMBER NORMALIZATION EDGE CASES\n","--------------------------------------------------\n","Input:  No:25D:4\n","Output: numara 25 daire 4\n","Input:  No: 5\n","Output: numara 5\n","Input:  No.25/A\n","Output: numara 25a\n","Input:  25/B\n","Output: 25b\n","Input:  D: 5\n","Output: daire 5\n","Input:  Daire 5\n","Output: daire 5\n","Input:  K: 2\n","Output: kat 2\n","Input:  Kat: 2\n","Output: kat: 2\n","Input:  birinci kat\n","Output: 1 kat\n","Input:  ikinci sokak\n","Output: 2 sokak\n","Input:  üçüncü cadde\n","Output: üçüncü cadde\n","\n","12. PERFORMANCE TEST\n","--------------------------------------------------\n","Processing 1300 addresses...\n","\n","Preprocessing Statistics:\n","Total addresses: 1300\n","Valid addresses: 1300\n","Processed 1300 addresses in 29.05 seconds\n","Speed: 45 addresses/second\n","\n","================================================================================\n","ALL TESTS COMPLETED SUCCESSFULLY!\n","================================================================================\n","component_coverage:\n","  number: 100.0%\n","  postal_code: 7.7%\n","  building_no: 92.3%\n","  apartment: 46.2%\n","  floor: 53.8%\n","  street: 100.0%\n","  district: 46.2%\n","\n","11. NUMBER NORMALIZATION EDGE CASES\n","--------------------------------------------------\n","Input:  No:25D:4\n","Output: numara 25 daire 4\n","Input:  No: 5\n","Output: numara 5\n","Input:  No.25/A\n","Output: numara 25a\n","Input:  25/B\n","Output: 25b\n","Input:  D: 5\n","Output: daire 5\n","Input:  Daire 5\n","Output: daire 5\n","Input:  K: 2\n","Output: kat 2\n","Input:  Kat: 2\n","Output: kat: 2\n","Input:  birinci kat\n","Output: 1 kat\n","Input:  ikinci sokak\n","Output: 2 sokak\n","Input:  üçüncü cadde\n","Output: üçüncü cadde\n","\n","12. PERFORMANCE TEST\n","--------------------------------------------------\n","Processing 1300 addresses...\n","\n","Preprocessing Statistics:\n","Total addresses: 1300\n","Valid addresses: 1300\n","Processed 1300 addresses in 28.97 seconds\n","Speed: 45 addresses/second\n","\n","================================================================================\n","ALL TESTS COMPLETED SUCCESSFULLY!\n","================================================================================\n","quality_metrics:\n","  avg_components: 5.615384615384615\n","  min_components: 4\n","  max_components: 7\n","\n","11. NUMBER NORMALIZATION EDGE CASES\n","--------------------------------------------------\n","Input:  No:25D:4\n","Output: numara 25 daire 4\n","Input:  No: 5\n","Output: numara 5\n","Input:  No.25/A\n","Output: numara 25a\n","Input:  25/B\n","Output: 25b\n","Input:  D: 5\n","Output: daire 5\n","Input:  Daire 5\n","Output: daire 5\n","Input:  K: 2\n","Output: kat 2\n","Input:  Kat: 2\n","Output: kat: 2\n","Input:  birinci kat\n","Output: 1 kat\n","Input:  ikinci sokak\n","Output: 2 sokak\n","Input:  üçüncü cadde\n","Output: üçüncü cadde\n","\n","12. PERFORMANCE TEST\n","--------------------------------------------------\n","Processing 1300 addresses...\n","\n","Preprocessing Statistics:\n","Total addresses: 1300\n","Valid addresses: 1300\n","Processed 1300 addresses in 28.98 seconds\n","Speed: 45 addresses/second\n","\n","================================================================================\n","ALL TESTS COMPLETED SUCCESSFULLY!\n","================================================================================\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","from typing import Dict, List, Tuple, Optional, Set\n","from unidecode import unidecode\n","from fuzzywuzzy import fuzz, process\n","from collections import defaultdict\n","import json\n","\n","class TurkishAddressProcessor:\n","    \"\"\"\n","    Comprehensive Turkish Address Processing Pipeline\n","    Türkçe adres işleme için gelişmiş ve kapsamlı bir sınıf\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"Initialize with comprehensive Turkish-specific configurations\"\"\"\n","\n","        # Turkish character mapping (extended)\n","        self.char_mapping = {\n","            'ç': 'c', 'Ç': 'C',\n","            'ğ': 'g', 'Ğ': 'G',\n","            'ı': 'i', 'İ': 'I', 'i̇': 'i',  # Handle different i variations\n","            'ö': 'o', 'Ö': 'O',\n","            'ş': 's', 'Ş': 'S',\n","            'ü': 'u', 'Ü': 'U',\n","            'â': 'a', 'Â': 'A',  # Circumflex characters\n","            'î': 'i', 'Î': 'I',\n","            'û': 'u', 'Û': 'U'\n","        }\n","\n","        # Comprehensive abbreviations dictionary\n","        self.abbreviations = {\n","            # Mahalle/District\n","            'mah': 'mahallesi', 'mh': 'mahallesi', 'mahl': 'mahallesi',\n","            'mah.': 'mahallesi', 'mh.': 'mahallesi', 'mahall': 'mahallesi',\n","\n","            # Cadde/Street\n","            'cd': 'caddesi', 'cad': 'caddesi', 'cadde': 'caddesi',\n","            'cd.': 'caddesi', 'cad.': 'caddesi', 'cadd': 'caddesi',\n","\n","            # Sokak/Street\n","            'sk': 'sokak', 'sok': 'sokak', 'sk.': 'sokak', 'sok.': 'sokak',\n","            'sokağı': 'sokak', 'sokagi': 'sokak',\n","\n","            # Bulvar/Boulevard\n","            'bulv': 'bulvar', 'blv': 'bulvar', 'bul': 'bulvar',\n","            'bulv.': 'bulvar', 'blv.': 'bulvar', 'bulvarı': 'bulvar',\n","\n","            # Apartman/Building\n","            'apt': 'apartmani', 'ap': 'apartmani', 'apt.': 'apartmani',\n","            'apart': 'apartmani', 'apartm': 'apartmani',\n","\n","            # Numara/Number\n","            'no': 'numara', 'no.': 'numara', 'nu': 'numara',\n","\n","            # Daire/Flat\n","            'd': 'daire', 'd.': 'daire', 'da': 'daire', 'dai': 'daire',\n","\n","            # Kat/Floor\n","            'k': 'kat', 'k.': 'kat', 'kt': 'kat',\n","\n","            # Blok/Block\n","            'bl': 'blok', 'blk': 'blok', 'bl.': 'blok',\n","\n","            # Site/Complex\n","            'sit': 'sitesi', 'site': 'sitesi', 'st': 'sitesi',\n","\n","            # İş Merkezi/Business Center\n","            'iş mrk': 'is merkezi', 'is mrk': 'is merkezi',\n","            'iş merk': 'is merkezi', 'is merk': 'is merkezi',\n","\n","            # Plaza\n","            'plz': 'plaza', 'plaz': 'plaza',\n","\n","            # Köy/Village\n","            'ky': 'koyu', 'köy': 'koyu', 'koy': 'koyu',\n","\n","            # Mevki/Location\n","            'mevk': 'mevkii', 'mvk': 'mevkii', 'mev': 'mevkii',\n","\n","            # Others\n","            'san': 'sanayi', 'sanay': 'sanayi',\n","            'org': 'organize', 'osb': 'organize sanayi bolgesi',\n","            'koop': 'kooperatifi', 'kop': 'kooperatifi',\n","            'müd': 'mudurlugu', 'mud': 'mudurlugu',\n","            'mrk': 'merkez', 'merk': 'merkez',\n","            'ünv': 'universitesi', 'unv': 'universitesi', 'üni': 'universitesi',\n","            'hst': 'hastanesi', 'has': 'hastanesi',\n","            'ilk': 'ilkokulu', 'ilkok': 'ilkokulu',\n","            'ort': 'ortaokulu', 'ortaok': 'ortaokulu',\n","            'lis': 'lisesi', 'lise': 'lisesi'\n","        }\n","\n","        # Extended typo corrections with city districts\n","        self.typo_corrections = {\n","            # Istanbul districts\n","            'uskudar': 'uskudar', 'üsküdar': 'uskudar', 'uskudr': 'uskudar',\n","            'kadikoy': 'kadikoy', 'kadıköy': 'kadikoy', 'kadiköy': 'kadikoy',\n","            'besiktas': 'besiktas', 'beşiktaş': 'besiktas', 'besiktaş': 'besiktas',\n","            'sisli': 'sisli', 'şişli': 'sisli', 'şişl': 'sisli',\n","            'beyoglu': 'beyoglu', 'beyoğlu': 'beyoglu', 'beyogl': 'beyoglu',\n","            'fatih': 'fatih', 'fatıh': 'fatih',\n","            'maltepe': 'maltepe', 'maltep': 'maltepe',\n","            'kartal': 'kartal', 'kartl': 'kartal',\n","            'pendik': 'pendik', 'pendık': 'pendik',\n","            'tuzla': 'tuzla', 'tuzl': 'tuzla',\n","            'cekmekoy': 'cekmekoy', 'çekmeköy': 'cekmekoy', 'cekmeköy': 'cekmekoy',\n","            'sancaktepe': 'sancaktepe', 'sancaktep': 'sancaktepe',\n","            'sultanbeyli': 'sultanbeyli', 'sultanbeylie': 'sultanbeyli',\n","            'umraniye': 'umraniye', 'ümraniye': 'umraniye', 'umranıye': 'umraniye',\n","            'atasehir': 'atasehir', 'ataşehir': 'atasehir', 'atasehır': 'atasehir',\n","            'bagcilar': 'bagcilar', 'bağcılar': 'bagcilar', 'bagcılar': 'bagcilar',\n","            'bahcelievler': 'bahcelievler', 'bahçelievler': 'bahcelievler',\n","            'bakirkoy': 'bakirkoy', 'bakırköy': 'bakirkoy', 'bakirköy': 'bakirkoy',\n","            'basaksehir': 'basaksehir', 'başakşehir': 'basaksehir',\n","            'bayrampasa': 'bayrampasa', 'bayrampaşa': 'bayrampasa',\n","            'esenler': 'esenler', 'esenlr': 'esenler',\n","            'esenyurt': 'esenyurt', 'esenyrt': 'esenyurt',\n","            'eyup': 'eyup', 'eyüp': 'eyup', 'eyupsultan': 'eyupsultan',\n","            'gaziosmanpasa': 'gaziosmanpasa', 'gaziosmanpaşa': 'gaziosmanpasa',\n","            'gungoren': 'gungoren', 'güngören': 'gungoren',\n","            'kucukcekmece': 'kucukcekmece', 'küçükçekmece': 'kucukcekmece',\n","            'sariyer': 'sariyer', 'sarıyer': 'sariyer', 'saryer': 'sariyer',\n","            'sultangazi': 'sultangazi', 'sultangaz': 'sultangazi',\n","            'zeytinburnu': 'zeytinburnu', 'zeytinbrnu': 'zeytinburnu',\n","            'avcilar': 'avcilar', 'avcılar': 'avcilar',\n","            'beylikduzu': 'beylikduzu', 'beylikdüzü': 'beylikduzu',\n","            'buyukcekmece': 'buyukcekmece', 'büyükçekmece': 'buyukcekmece',\n","            'kagithane': 'kagithane', 'kağıthane': 'kagithane',\n","\n","            # Major cities\n","            'ankara': 'ankara', 'ankra': 'ankara', 'ank': 'ankara',\n","            'izmir': 'izmir', 'izmır': 'izmir', 'izmr': 'izmir',\n","            'istanbul': 'istanbul', 'istanbl': 'istanbul', 'ist': 'istanbul',\n","            'bursa': 'bursa', 'brsa': 'bursa',\n","            'antalya': 'antalya', 'antalyaa': 'antalya', 'antaly': 'antalya',\n","            'adana': 'adana', 'adna': 'adana',\n","            'konya': 'konya', 'knya': 'konya',\n","            'gaziantep': 'gaziantep', 'gazi antep': 'gaziantep', 'antep': 'gaziantep',\n","            'kayseri': 'kayseri', 'kayser': 'kayseri',\n","            'eskisehir': 'eskisehir', 'eskişehir': 'eskisehir',\n","            'trabzon': 'trabzon', 'trabzn': 'trabzon',\n","            'samsun': 'samsun', 'samsn': 'samsun',\n","\n","            # Common street names\n","            'ataturk': 'ataturk', 'atatürk': 'ataturk', 'atatrk': 'ataturk',\n","            'cumhuriyet': 'cumhuriyet', 'cumhuryet': 'cumhuriyet', 'cumhriyet': 'cumhuriyet',\n","            'istiklal': 'istiklal', 'istıklal': 'istiklal', 'istikal': 'istiklal',\n","            'inonu': 'inonu', 'inönü': 'inonu', 'ınonu': 'inonu',\n","            'menderes': 'menderes', 'menders': 'menderes'\n","        }\n","\n","        # Turkish stopwords (extended)\n","        self.stopwords = {\n","            'il', 'ilce', 'ilcesi', 'ili', 'ilimiz', 'ilcemiz',\n","            'turkiye', 'turkey', 'tr', 'tc',\n","            'posta', 'kodu', 'pk', 'postakodu',\n","            've', 'veya', 'ya', 'da', 'de', 'ki', 'ile',\n","            'karsi', 'karsisi', 'yani', 'yaninda', 'arkasi', 'arkasinda',\n","            'ustu', 'ustunde', 'alti', 'altinda', 'ici', 'icinde',\n","            'dis', 'disinda', 'on', 'onunde', 'arka', 'arkada',\n","            'ust', 'alt', 'yan', 'kose', 'kosesi', 'kosesinde',\n","            'bitisik', 'bitisigi', 'civari', 'civarinda', 'yakini', 'yakininda'\n","        }\n","\n","        # Address component patterns (enhanced)\n","        self.patterns = {\n","            'postal_code': r'\\b\\d{5}\\b',\n","            'phone': r'(?:\\+90|0)?[\\s-]?\\d{3}[\\s-]?\\d{3}[\\s-]?\\d{2}[\\s-]?\\d{2}',\n","            'floor': r'(?:kat|k\\.?)\\s*[:.]?\\s*(\\d+|zemin|bodrum|giris|ara)',\n","            'apartment': r'(?:daire|d\\.?|dai\\.?)\\s*[:.]?\\s*(\\d+[a-zA-Z]?)',\n","            'building_no': r'(?:no|numara|nu\\.?)\\s*[:.]?\\s*(\\d+[a-zA-Z]?(?:[/-]\\d+[a-zA-Z]?)?)',\n","            'block': r'(?:blok|bl\\.?|blk\\.?)\\s*[:.]?\\s*([a-zA-Z]\\d*|\\d+[a-zA-Z]?)',\n","            'district': r'(\\w+(?:\\s+\\w+)*?)\\s*(?:mahalle|mahallesi|mah\\.?|mh\\.?)',\n","            'street': r'(\\w+(?:\\s+\\w+)*?)\\s*(?:sokak|sokagi|sok\\.?|sk\\.?|caddesi|cad\\.?|cd\\.?|bulvar|bulvari|bulv\\.?|blv\\.?)',\n","            'site': r'(\\w+(?:\\s+\\w+)*?)\\s*(?:sitesi|site|sit\\.?)',\n","            'plaza': r'(\\w+(?:\\s+\\w+)*?)\\s*(?:plaza|plz\\.?|plaz\\.?)',\n","            'apartment_name': r'(\\w+(?:\\s+\\w+)*?)\\s*(?:apartmani|apartman|apt\\.?|ap\\.?)',\n","            'village': r'(\\w+(?:\\s+\\w+)*?)\\s*(?:koyu|koy|ky\\.?)',\n","            'neighborhood': r'(\\w+(?:\\s+\\w+)*?)\\s*(?:mevkii|mevki|mevk\\.?|mvk\\.?)',\n","            'district_name': r'(\\w+)\\s*(?:ilcesi|ilce|ilc\\.?)',\n","            'city_name': r'(\\w+)\\s*(?:ili|il|sehri|sehir|kent)'\n","        }\n","\n","        # City and district hierarchy\n","        self.city_hierarchy = {\n","            'istanbul': {\n","                'european': ['fatih', 'beyoglu', 'besiktas', 'sisli', 'kagithane', 'eyup',\n","                           'gaziosmanpasa', 'esenler', 'gungoren', 'bagcilar', 'bahcelievler',\n","                           'bakirkoy', 'zeytinburnu', 'kucukcekmece', 'avcilar', 'esenyurt',\n","                           'beylikduzu', 'buyukcekmece', 'basaksehir', 'arnavutkoy', 'sultangazi',\n","                           'bayrampasa', 'sariyer'],\n","                'asian': ['kadikoy', 'uskudar', 'umraniye', 'kartal', 'maltepe', 'pendik',\n","                         'tuzla', 'atasehir', 'cekmekoy', 'sancaktepe', 'sultanbeyli', 'sile',\n","                         'beykoz', 'adalar']\n","            },\n","            'ankara': {\n","                'merkez': ['cankaya', 'kecioren', 'yenimahalle', 'mamak', 'etimesgut',\n","                          'sincan', 'altindag', 'pursaklar', 'golbasi'],\n","                'ilce': ['polatli', 'beypazari', 'ayas', 'bala', 'camlidere', 'cubuk',\n","                        'elmadag', 'gudul', 'haymana', 'kahramankazan', 'kalecik',\n","                        'kizilcahamam', 'nallihan', 'sereflikochisar']\n","            },\n","            'izmir': {\n","                'merkez': ['konak', 'bornova', 'buca', 'karsiyaka', 'cigli', 'gaziemir',\n","                          'narlidere', 'balcova', 'bayrakli', 'karabaglar', 'guzelbahce'],\n","                'ilce': ['aliaga', 'bayindir', 'bergama', 'beydag', 'cesme', 'dikili',\n","                        'foca', 'karaburun', 'kemalpasa', 'kinik', 'kiraz', 'menderes',\n","                        'menemen', 'odemis', 'seferihisar', 'selcuk', 'tire', 'torbali', 'urla']\n","            }\n","        }\n","\n","        # Common building types\n","        self.building_types = {\n","            'residence': ['residence', 'residance', 'rezidans', 'rezidence', 'konutlari', 'evleri'],\n","            'site': ['sitesi', 'site', 'konakları', 'konaklari', 'villaları', 'villalari'],\n","            'plaza': ['plaza', 'plz', 'plaza', 'tower', 'towers', 'kule', 'kulesi'],\n","            'merkez': ['merkezi', 'merkez', 'center', 'centre', 'mall', 'avm'],\n","            'is_merkezi': ['is merkezi', 'is hani', 'ishani', 'ticaret merkezi', 'ofis'],\n","            'apartman': ['apartmani', 'apartman', 'apt', 'blok', 'binasi']\n","        }\n","\n","        # Direction words\n","        self.direction_words = {\n","            'kuzey': ['kuzey', 'k', 'north'],\n","            'guney': ['guney', 'g', 'south'],\n","            'dogu': ['dogu', 'd', 'east'],\n","            'bati': ['bati', 'b', 'west'],\n","            'merkez': ['merkez', 'orta', 'center', 'central'],\n","            'yukarı': ['yukari', 'ust', 'upper'],\n","            'asagi': ['asagi', 'alt', 'lower'],\n","            'yeni': ['yeni', 'new'],\n","            'eski': ['eski', 'old']\n","        }\n","\n","        # Number words in Turkish\n","        self.number_words = {\n","            'bir': '1', 'iki': '2', 'uc': '3', 'dort': '4', 'bes': '5',\n","            'alti': '6', 'yedi': '7', 'sekiz': '8', 'dokuz': '9', 'on': '10',\n","            'onbir': '11', 'oniki': '12', 'onuc': '13', 'ondort': '14', 'onbes': '15',\n","            'yirmi': '20', 'otuz': '30', 'kirk': '40', 'elli': '50',\n","            'altmis': '60', 'yetmis': '70', 'seksen': '80', 'doksan': '90',\n","            'yuz': '100', 'birinci': '1', 'ikinci': '2', 'ucuncu': '3',\n","            'dorduncu': '4', 'besinci': '5', 'altinci': '6', 'yedinci': '7',\n","            'sekizinci': '8', 'dokuzuncu': '9', 'onuncu': '10'\n","        }\n","\n","        # Common prefixes and suffixes\n","        self.address_prefixes = ['yeni', 'eski', 'buyuk', 'kucuk', 'orta', 'asagi', 'yukari',\n","                                'ic', 'dis', 'uzeri', 'alti', 'kuzey', 'guney', 'dogu', 'bati']\n","\n","        self.address_suffixes = ['mahallesi', 'caddesi', 'sokagi', 'sokak', 'bulvari', 'yolu',\n","                                'meydani', 'parki', 'bahcesi', 'konaklari', 'evleri', 'sitesi']\n","\n","    def normalize_turkish_chars(self, text: str) -> str:\n","        \"\"\"Normalize Turkish characters to ASCII equivalents\"\"\"\n","        if not text:\n","            return text\n","\n","        # Apply character mapping\n","        for turkish, latin in self.char_mapping.items():\n","            text = text.replace(turkish, latin)\n","\n","        # Handle special cases\n","        text = text.replace('İ', 'I').replace('i̇', 'i')\n","\n","        return text\n","\n","    def expand_abbreviations(self, text: str) -> str:\n","        \"\"\"Expand common Turkish address abbreviations\"\"\"\n","        if not text:\n","            return text\n","\n","        # Create boundary pattern for whole word matching\n","        for abbr, full in sorted(self.abbreviations.items(), key=lambda x: len(x[0]), reverse=True):\n","            # Match abbreviation with word boundaries\n","            pattern = r'\\b' + re.escape(abbr) + r'\\.?\\b'\n","            text = re.sub(pattern, full, text, flags=re.IGNORECASE)\n","\n","        return text\n","\n","    def normalize_numbers(self, text: str) -> str:\n","        \"\"\"Advanced number normalization for Turkish addresses\"\"\"\n","        if not text:\n","            return text\n","\n","        # Convert number words to digits\n","        for word, digit in self.number_words.items():\n","            pattern = r'\\b' + word + r'\\b'\n","            text = re.sub(pattern, digit, text, flags=re.IGNORECASE)\n","\n","        # Handle special number patterns\n","        # No:25D:4 → numara 25 daire 4\n","        text = re.sub(r'no\\s*[;:]\\s*(\\d+)\\s*d\\s*[:;]\\s*(\\d+)', r'numara \\1 daire \\2', text, flags=re.IGNORECASE)\n","\n","        # No/25 or No.25 → numara 25\n","        text = re.sub(r'no\\s*[\\./:]\\s*(\\d+)', r'numara \\1', text, flags=re.IGNORECASE)\n","\n","        # 25/A or 25-A → 25A\n","        text = re.sub(r'(\\d+)\\s*[/-]\\s*([a-zA-Z])', r'\\1\\2', text)\n","\n","        # D:5 or D.5 → daire 5\n","        text = re.sub(r'\\bd\\s*[:\\.]\\s*(\\d+)', r'daire \\1', text, flags=re.IGNORECASE)\n","\n","        # K:2 or K.2 → kat 2\n","        text = re.sub(r'\\bk\\s*[:\\.]\\s*(\\d+)', r'kat \\1', text, flags=re.IGNORECASE)\n","\n","        # Blok A → blok A\n","        text = re.sub(r'blok\\s+([a-zA-Z]\\d*)', r'blok \\1', text, flags=re.IGNORECASE)\n","\n","        # Handle floor names\n","        text = re.sub(r'\\b(zemin|bodrum|giris|ara)\\s+kat\\b', r'\\1kat', text, flags=re.IGNORECASE)\n","\n","        return text\n","\n","    def fix_common_typos(self, text: str) -> str:\n","        \"\"\"Fix common typos using advanced fuzzy matching\"\"\"\n","        if not text:\n","            return text\n","\n","        words = text.split()\n","        fixed_words = []\n","\n","        for word in words:\n","            clean_word = word.lower().strip()\n","\n","            # Skip short words and numbers\n","            if len(clean_word) <= 3 or clean_word.isdigit():\n","                fixed_words.append(word)\n","                continue\n","\n","            # Check against typo corrections\n","            best_match = None\n","            best_score = 0\n","\n","            for typo, correct in self.typo_corrections.items():\n","                score = fuzz.ratio(clean_word, typo)\n","                if score > best_score and score >= 85:\n","                    best_score = score\n","                    best_match = correct\n","\n","            if best_match:\n","                fixed_words.append(best_match)\n","            else:\n","                fixed_words.append(word)\n","\n","        return ' '.join(fixed_words)\n","\n","    def remove_stopwords(self, text: str) -> str:\n","        \"\"\"Remove Turkish stopwords while preserving important address components\"\"\"\n","        if not text:\n","            return text\n","\n","        words = text.split()\n","        filtered_words = []\n","\n","        for i, word in enumerate(words):\n","            # Don't remove stopwords if they're part of an address component\n","            if word.lower() in self.stopwords:\n","                # Check if it's part of a meaningful phrase\n","                if i > 0 and words[i-1].lower() in ['posta', 'il', 'ilce']:\n","                    filtered_words.append(word)\n","                else:\n","                    continue\n","            else:\n","                filtered_words.append(word)\n","\n","        return ' '.join(filtered_words)\n","\n","    def extract_address_components(self, text: str) -> Dict[str, str]:\n","        \"\"\"Extract structured components from Turkish address text\"\"\"\n","        components = {}\n","\n","        # Extract patterns\n","        for component, pattern in self.patterns.items():\n","            matches = re.findall(pattern, text, re.IGNORECASE)\n","            if matches:\n","                # Get the best match (usually the first one)\n","                if isinstance(matches[0], tuple):\n","                    components[component] = matches[0][0]\n","                else:\n","                    components[component] = matches[0]\n","\n","        # Extract city and district from hierarchy\n","        text_lower = text.lower()\n","        for city, districts in self.city_hierarchy.items():\n","            if city in text_lower:\n","                components['city'] = city\n","                # Check districts\n","                all_districts = []\n","                for region, district_list in districts.items():\n","                    all_districts.extend(district_list)\n","\n","                for district in all_districts:\n","                    if district in text_lower:\n","                        components['district_name'] = district\n","                        break\n","                break\n","\n","        return components\n","\n","    def parse_address_hierarchy(self, text: str) -> Dict[str, str]:\n","        \"\"\"Parse address into hierarchical components\"\"\"\n","        hierarchy = {\n","            'country': 'turkiye',\n","            'city': None,\n","            'district': None,\n","            'neighborhood': None,\n","            'street': None,\n","            'building': None,\n","            'floor': None,\n","            'apartment': None\n","        }\n","\n","        # Extract components\n","        components = self.extract_address_components(text)\n","\n","        # Map components to hierarchy\n","        if 'city_name' in components:\n","            hierarchy['city'] = components['city_name']\n","        elif 'city' in components:\n","            hierarchy['city'] = components['city']\n","\n","        if 'district_name' in components:\n","            hierarchy['district'] = components['district_name']\n","\n","        if 'district' in components:\n","            hierarchy['neighborhood'] = components['district']\n","\n","        if 'street' in components:\n","            hierarchy['street'] = components['street']\n","\n","        if 'building_no' in components:\n","            hierarchy['building'] = components['building_no']\n","\n","        if 'floor' in components:\n","            hierarchy['floor'] = components['floor']\n","\n","        if 'apartment' in components:\n","            hierarchy['apartment'] = components['apartment']\n","\n","        return hierarchy\n","\n","    def standardize_address_format(self, text: str) -> str:\n","        \"\"\"Standardize address to a consistent format\"\"\"\n","        # Parse hierarchy\n","        hierarchy = self.parse_address_hierarchy(text)\n","\n","        # Build standardized address\n","        parts = []\n","\n","        if hierarchy['neighborhood']:\n","            parts.append(f\"{hierarchy['neighborhood']} mahallesi\")\n","\n","        if hierarchy['street']:\n","            parts.append(hierarchy['street'])\n","\n","        if hierarchy['building']:\n","            parts.append(f\"numara {hierarchy['building']}\")\n","\n","        if hierarchy['floor']:\n","            parts.append(f\"kat {hierarchy['floor']}\")\n","\n","        if hierarchy['apartment']:\n","            parts.append(f\"daire {hierarchy['apartment']}\")\n","\n","        if hierarchy['district']:\n","            parts.append(hierarchy['district'])\n","\n","        if hierarchy['city']:\n","            parts.append(hierarchy['city'])\n","\n","        return ' '.join(parts)\n","\n","    def calculate_component_similarity(self, addr1: str, addr2: str) -> Dict[str, float]:\n","        \"\"\"Calculate similarity scores for each address component\"\"\"\n","        comp1 = self.extract_address_components(addr1)\n","        comp2 = self.extract_address_components(addr2)\n","\n","        similarity_scores = {}\n","\n","        # Check each component type\n","        component_types = set(comp1.keys()) | set(comp2.keys())\n","\n","        for comp_type in component_types:\n","            val1 = comp1.get(comp_type, '')\n","            val2 = comp2.get(comp_type, '')\n","\n","            if val1 and val2:\n","                # Use different similarity measures based on component type\n","                if comp_type in ['building_no', 'floor', 'apartment', 'postal_code']:\n","                    # Exact match for numbers\n","                    similarity_scores[comp_type] = 1.0 if val1 == val2 else 0.0\n","                else:\n","                    # Fuzzy match for text\n","                    similarity_scores[comp_type] = fuzz.ratio(val1, val2) / 100.0\n","            else:\n","                similarity_scores[comp_type] = 0.0\n","\n","        return similarity_scores\n","\n","    def is_valid_turkish_address(self, text: str) -> bool:\n","        \"\"\"Validate if text contains minimum required Turkish address components\"\"\"\n","        if not text or len(text) < 10:\n","            return False\n","\n","        # Check for minimum components\n","        components = self.extract_address_components(text)\n","\n","        # Must have at least a street/district and city/district name\n","        has_location = any(key in components for key in ['street', 'district', 'district_name'])\n","        has_area = any(key in components for key in ['city_name', 'city', 'district_name'])\n","\n","        return has_location or has_area\n","\n","    def preprocess_address(self, text: str, standardize: bool = False) -> str:\n","        \"\"\"\n","        Main preprocessing function with all cleaning steps\n","\n","        Args:\n","            text (str): Raw address text\n","            standardize (bool): Whether to apply standardization\n","\n","        Returns:\n","            str: Cleaned and normalized address\n","        \"\"\"\n","        if pd.isna(text) or text == '' or text == '-----':\n","            return ''\n","\n","        # Convert to string and clean\n","        text = str(text).strip()\n","\n","        # Remove multiple spaces and normalize whitespace\n","        text = ' '.join(text.split())\n","\n","        # Convert to lowercase\n","        text = text.lower()\n","\n","        # Normalize Turkish characters\n","        text = self.normalize_turkish_chars(text)\n","\n","        # Expand abbreviations\n","        text = self.expand_abbreviations(text)\n","\n","        # Normalize numbers\n","        text = self.normalize_numbers(text)\n","\n","        # Remove extra punctuation but keep necessary ones\n","        text = re.sub(r'[^\\w\\s/\\-]', ' ', text)\n","\n","        # Fix common typos\n","        text = self.fix_common_typos(text)\n","\n","        # Normalize whitespace again\n","        text = ' '.join(text.split())\n","\n","        # Optionally remove stopwords\n","        # text = self.remove_stopwords(text)\n","\n","        # Optionally standardize format\n","        if standardize and self.is_valid_turkish_address(text):\n","            text = self.standardize_address_format(text)\n","\n","        return text.strip()\n","\n","    def get_address_features(self, text: str) -> Dict[str, any]:\n","        \"\"\"Extract comprehensive features from address text\"\"\"\n","        features = {\n","            'length': len(text),\n","            'word_count': len(text.split()),\n","            'has_number': bool(re.search(r'\\d', text)),\n","            'components': self.extract_address_components(text),\n","            'hierarchy': self.parse_address_hierarchy(text),\n","            'is_valid': self.is_valid_turkish_address(text)\n","        }\n","\n","        # Count component types\n","        features['component_count'] = len([v for v in features['components'].values() if v])\n","\n","        # Check for specific patterns\n","        features['has_postal_code'] = 'postal_code' in features['components']\n","        features['has_building_no'] = 'building_no' in features['components']\n","        features['has_apartment'] = 'apartment' in features['components']\n","        features['has_floor'] = 'floor' in features['components']\n","        features['has_street'] = 'street' in features['components']\n","        features['has_district'] = 'district' in features['components']\n","\n","        # Check for building types\n","        text_lower = text.lower()\n","        for btype, keywords in self.building_types.items():\n","            features[f'has_{btype}'] = any(keyword in text_lower for keyword in keywords)\n","\n","        # Check for direction words\n","        for direction, keywords in self.direction_words.items():\n","            features[f'has_{direction}'] = any(keyword in text_lower for keyword in keywords)\n","\n","        return features\n","\n","    def fuzzy_match_addresses(self, addr1: str, addr2: str, threshold: float = 0.8) -> Tuple[bool, float]:\n","        \"\"\"\n","        Advanced fuzzy matching between two addresses\n","\n","        Returns:\n","            Tuple[bool, float]: (is_match, similarity_score)\n","        \"\"\"\n","        # Preprocess both addresses\n","        proc_addr1 = self.preprocess_address(addr1)\n","        proc_addr2 = self.preprocess_address(addr2)\n","\n","        # If either is empty after preprocessing, no match\n","        if not proc_addr1 or not proc_addr2:\n","            return False, 0.0\n","\n","        # Calculate different similarity metrics\n","        scores = []\n","\n","        # 1. Overall string similarity\n","        string_sim = fuzz.ratio(proc_addr1, proc_addr2) / 100.0\n","        scores.append(('string', string_sim, 0.3))\n","\n","        # 2. Token set similarity (order-independent)\n","        token_sim = fuzz.token_set_ratio(proc_addr1, proc_addr2) / 100.0\n","        scores.append(('token', token_sim, 0.3))\n","\n","        # 3. Component-based similarity\n","        comp_similarities = self.calculate_component_similarity(addr1, addr2)\n","        if comp_similarities:\n","            comp_sim = sum(comp_similarities.values()) / len(comp_similarities)\n","            scores.append(('component', comp_sim, 0.4))\n","\n","        # Calculate weighted average\n","        total_score = sum(score * weight for _, score, weight in scores)\n","\n","        # Check if it's a match\n","        is_match = total_score >= threshold\n","\n","        return is_match, total_score\n","\n","    def group_similar_addresses(self, addresses: List[str], threshold: float = 0.85) -> Dict[int, List[int]]:\n","        \"\"\"\n","        Group similar addresses together\n","\n","        Returns:\n","            Dict mapping group_id to list of address indices\n","        \"\"\"\n","        n_addresses = len(addresses)\n","        groups = {}\n","        assigned = set()\n","        group_id = 0\n","\n","        for i in range(n_addresses):\n","            if i in assigned:\n","                continue\n","\n","            # Start new group\n","            groups[group_id] = [i]\n","            assigned.add(i)\n","\n","            # Find similar addresses\n","            for j in range(i + 1, n_addresses):\n","                if j not in assigned:\n","                    is_match, score = self.fuzzy_match_addresses(addresses[i], addresses[j], threshold)\n","                    if is_match:\n","                        groups[group_id].append(j)\n","                        assigned.add(j)\n","\n","            group_id += 1\n","\n","        return groups\n","\n","    def preprocess_dataframe(self, df: pd.DataFrame, address_col: str = 'address',\n","                           extract_features: bool = True,\n","                           remove_duplicates: bool = True) -> pd.DataFrame:\n","        \"\"\"\n","        Advanced preprocessing for entire dataframe\n","\n","        Args:\n","            df (pd.DataFrame): Input dataframe\n","            address_col (str): Name of address column\n","            extract_features (bool): Whether to extract address features\n","            remove_duplicates (bool): Whether to mark duplicates\n","\n","        Returns:\n","            pd.DataFrame: Processed dataframe with additional columns\n","        \"\"\"\n","        # Create a copy\n","        df_processed = df.copy()\n","\n","        print(f\"Processing {len(df)} addresses...\")\n","\n","        # Apply preprocessing\n","        df_processed['processed_address'] = df_processed[address_col].apply(\n","            lambda x: self.preprocess_address(x, standardize=False)\n","        )\n","\n","        # Apply standardization separately\n","        df_processed['standardized_address'] = df_processed[address_col].apply(\n","            lambda x: self.preprocess_address(x, standardize=True)\n","        )\n","\n","        # Extract features if requested\n","        if extract_features:\n","            print(\"Extracting address features...\")\n","            features_list = []\n","\n","            for idx, row in df_processed.iterrows():\n","                features = self.get_address_features(row['processed_address'])\n","                features_list.append(features)\n","\n","                if idx % 10000 == 0 and idx > 0:\n","                    print(f\"  Processed {idx} addresses...\")\n","\n","            # Convert features to columns\n","            features_df = pd.DataFrame(features_list)\n","\n","            # Add feature columns\n","            for col in ['length', 'word_count', 'component_count', 'has_number', 'is_valid',\n","                       'has_postal_code', 'has_building_no', 'has_apartment', 'has_floor',\n","                       'has_street', 'has_district']:\n","                if col in features_df.columns:\n","                    df_processed[f'feat_{col}'] = features_df[col]\n","\n","        # Mark duplicates if requested\n","        if remove_duplicates:\n","            # Check for exact duplicates\n","            df_processed['is_duplicate_exact'] = df_processed.duplicated(\n","                subset=['processed_address'], keep='first'\n","            )\n","\n","            # Check for standardized duplicates\n","            df_processed['is_duplicate_standard'] = df_processed.duplicated(\n","                subset=['standardized_address'], keep='first'\n","            )\n","\n","            # Calculate fuzzy duplicates for a sample (expensive operation)\n","            if len(df_processed) < 10000:\n","                print(\"Detecting fuzzy duplicates...\")\n","                addresses = df_processed['processed_address'].tolist()\n","                groups = self.group_similar_addresses(addresses, threshold=0.9)\n","\n","                # Mark fuzzy duplicates\n","                fuzzy_dup = [False] * len(df_processed)\n","                for group_id, indices in groups.items():\n","                    if len(indices) > 1:\n","                        # Keep first, mark rest as duplicates\n","                        for idx in indices[1:]:\n","                            fuzzy_dup[idx] = True\n","\n","                df_processed['is_duplicate_fuzzy'] = fuzzy_dup\n","\n","        # Add validation flag\n","        df_processed['is_valid_address'] = df_processed['processed_address'].apply(\n","            self.is_valid_turkish_address\n","        )\n","\n","        # Statistics\n","        print(\"\\nPreprocessing Statistics:\")\n","        print(f\"Total addresses: {len(df_processed)}\")\n","        print(f\"Valid addresses: {df_processed['is_valid_address'].sum()}\")\n","\n","        if remove_duplicates:\n","            print(f\"Exact duplicates: {df_processed['is_duplicate_exact'].sum()}\")\n","            print(f\"Standardized duplicates: {df_processed['is_duplicate_standard'].sum()}\")\n","            if 'is_duplicate_fuzzy' in df_processed.columns:\n","                print(f\"Fuzzy duplicates: {df_processed['is_duplicate_fuzzy'].sum()}\")\n","\n","        return df_processed\n","\n","    def generate_address_report(self, df: pd.DataFrame) -> Dict[str, any]:\n","        \"\"\"Generate comprehensive report on address data quality\"\"\"\n","        report = {\n","            'total_addresses': int(len(df)),  # int64'ü int'e çevir\n","            'processed_addresses': int(len(df[df['processed_address'] != ''])),\n","            'valid_addresses': int(df['is_valid_address'].sum()) if 'is_valid_address' in df.columns else 0,\n","            'statistics': {},\n","            'component_coverage': {},\n","            'quality_metrics': {}\n","        }\n","\n","        # Component coverage\n","        if 'feat_has_street' in df.columns:\n","            component_cols = [col for col in df.columns if col.startswith('feat_has_')]\n","            for col in component_cols:\n","                component_name = col.replace('feat_has_', '')\n","                coverage = df[col].sum() / len(df) * 100\n","                report['component_coverage'][component_name] = f\"{coverage:.1f}%\"\n","\n","        # Quality metrics\n","        if 'feat_component_count' in df.columns:\n","            report['quality_metrics']['avg_components'] = float(df['feat_component_count'].mean())\n","            report['quality_metrics']['min_components'] = int(df['feat_component_count'].min())\n","            report['quality_metrics']['max_components'] = int(df['feat_component_count'].max())\n","\n","        # Address length statistics\n","        if 'feat_length' in df.columns:\n","            report['statistics']['avg_length'] = float(df['feat_length'].mean())\n","            report['statistics']['min_length'] = int(df['feat_length'].min())\n","            report['statistics']['max_length'] = int(df['feat_length'].max())\n","\n","        # Word count statistics\n","        if 'feat_word_count' in df.columns:\n","            report['statistics']['avg_words'] = float(df['feat_word_count'].mean())\n","            report['statistics']['min_words'] = int(df['feat_word_count'].min())\n","            report['statistics']['max_words'] = int(df['feat_word_count'].max())\n","\n","        return report\n","\n","\n","# Example usage and testing\n","if __name__ == \"__main__\":\n","    # Initialize processor\n","    processor = TurkishAddressProcessor()\n","\n","    # Test cases\n","    test_addresses = [\n","        \"Çankaya Mah. Atatürk Bulv. No:125/A D:3 K:2 Ankara\",\n","        \"Kadıköy İskele Cd. No:10/B İstanbul\",\n","        \"Narlıdere Mah. Mithatpaşa Cd. No:15/A D:3 K:2 İzmir\",\n","        \"Fatih mah menderes bul No;25D:4\",\n","        \"YENİ MAH. ESKİ SOK. APT. NO:5 DAİRE:3 KAT:2\",\n","        \"Uskudar Meydan Sk. Yeni Plaza K:5 Istanbul\",\n","        \"Beşiktaş Barbaros Bulvarı No:145 Kat:3 Daire:12 İSTANBUL\",\n","        \"atatürk mahallesi cumhuriyet caddesi no 25 daire 4 ankara\",\n","        \"Karşıyaka Çarşı Sok. No:5 İzmir\",\n","        \"Bakırköy İstasyon Cad. Güneş Apt. No:22/5 İstanbul\",\n","        \"Üsküdar Çarşı Mh. İskele Sk. No:10 İSTANBUL\",\n","        \"BAHÇELİEVLER 7. CAD. NO:15/B ÇANKAYA/ANKARA\",\n","        \"Yeşilköy Havalimanı Cd. No:11/1 Bakırköy İstanbul 34149\"\n","    ]\n","\n","    print(\"=\" * 80)\n","    print(\"TURKISH ADDRESS PROCESSOR - COMPREHENSIVE TEST\")\n","    print(\"=\" * 80)\n","\n","    # Test 1: Basic preprocessing\n","    print(\"\\n1. BASIC PREPROCESSING TEST\")\n","    print(\"-\" * 50)\n","    for addr in test_addresses[:5]:\n","        processed = processor.preprocess_address(addr)\n","        print(f\"Original:  {addr}\")\n","        print(f\"Processed: {processed}\")\n","        print()\n","\n","    # Test 2: Standardization\n","    print(\"\\n2. ADDRESS STANDARDIZATION TEST\")\n","    print(\"-\" * 50)\n","    for addr in test_addresses[:5]:\n","        standardized = processor.preprocess_address(addr, standardize=True)\n","        print(f\"Original:     {addr}\")\n","        print(f\"Standardized: {standardized}\")\n","        print()\n","\n","    # Test 3: Component extraction\n","    print(\"\\n3. COMPONENT EXTRACTION TEST\")\n","    print(\"-\" * 50)\n","    for addr in test_addresses[:3]:\n","        components = processor.extract_address_components(processor.preprocess_address(addr))\n","        print(f\"Address: {addr}\")\n","        print(\"Components:\")\n","        for comp, value in components.items():\n","            print(f\"  {comp}: {value}\")\n","        print()\n","\n","    # Test 4: Address hierarchy\n","    print(\"\\n4. ADDRESS HIERARCHY TEST\")\n","    print(\"-\" * 50)\n","    for addr in test_addresses[:3]:\n","        hierarchy = processor.parse_address_hierarchy(processor.preprocess_address(addr))\n","        print(f\"Address: {addr}\")\n","        print(\"Hierarchy:\")\n","        for level, value in hierarchy.items():\n","            if value:\n","                print(f\"  {level}: {value}\")\n","        print()\n","\n","    # Test 5: Similarity calculation\n","    print(\"\\n5. ADDRESS SIMILARITY TEST\")\n","    print(\"-\" * 50)\n","    test_pairs = [\n","        (test_addresses[0], \"Çankaya Mahallesi Atatürk Bulvarı 125A Daire 3 Ankara\"),\n","        (test_addresses[1], \"kadikoy iskele caddesi no 10B istanbul\"),\n","        (test_addresses[6], \"Beşiktaş Barbaros Bulv. No:145 D:12 K:3 İstanbul\"),\n","        (\"Atatürk Mah. İnönü Sok. No:25 Ankara\", \"atatürk mahallesi inönü sokak 25 ankara\")\n","    ]\n","\n","    for addr1, addr2 in test_pairs:\n","        is_match, score = processor.fuzzy_match_addresses(addr1, addr2)\n","        print(f\"Address 1: {addr1}\")\n","        print(f\"Address 2: {addr2}\")\n","        print(f\"Match: {'YES' if is_match else 'NO'} (Score: {score:.2%})\")\n","\n","        # Component similarities\n","        comp_sim = processor.calculate_component_similarity(\n","            processor.preprocess_address(addr1),\n","            processor.preprocess_address(addr2)\n","        )\n","        if comp_sim:\n","            print(\"Component similarities:\")\n","            for comp, sim in comp_sim.items():\n","                print(f\"  {comp}: {sim:.2%}\")\n","        print()\n","\n","    # Test 6: Feature extraction\n","    print(\"\\n6. FEATURE EXTRACTION TEST\")\n","    print(\"-\" * 50)\n","    for addr in test_addresses[:3]:\n","        features = processor.get_address_features(processor.preprocess_address(addr))\n","        print(f\"Address: {addr}\")\n","        print(f\"Features:\")\n","        print(f\"  Length: {features['length']}\")\n","        print(f\"  Words: {features['word_count']}\")\n","        print(f\"  Components: {features['component_count']}\")\n","        print(f\"  Valid: {features['is_valid']}\")\n","        print(f\"  Has Number: {features['has_number']}\")\n","        print()\n","\n","    # Test 7: Batch processing\n","    print(\"\\n7. BATCH PROCESSING TEST\")\n","    print(\"-\" * 50)\n","    test_df = pd.DataFrame({'address': test_addresses})\n","    processed_df = processor.preprocess_dataframe(test_df, extract_features=True)\n","\n","    print(f\"Processed {len(processed_df)} addresses\")\n","    print(\"\\nDataFrame columns:\")\n","    print(processed_df.columns.tolist())\n","\n","    print(\"\\nSample results:\")\n","    display_cols = ['address', 'processed_address', 'feat_component_count', 'is_valid_address']\n","    print(processed_df[display_cols].head(3).to_string())\n","\n","    # Test 8: Duplicate detection\n","    print(\"\\n8. DUPLICATE DETECTION TEST\")\n","    print(\"-\" * 50)\n","    dup_addresses = [\n","        \"Kadıköy İskele Cad. No:10 İstanbul\",\n","        \"kadikoy iskele caddesi no 10 istanbul\",\n","        \"KADIKOY ISKELE CAD NO:10 ISTANBUL\",\n","        \"Bakırköy İstasyon Cad. No:22 İstanbul\",\n","        \"bakirkoy istasyon caddesi no 22 istanbul\"\n","    ]\n","\n","    dup_df = pd.DataFrame({'address': dup_addresses})\n","    dup_processed = processor.preprocess_dataframe(dup_df, remove_duplicates=True)\n","\n","    print(\"Duplicate analysis:\")\n","    for idx, row in dup_processed.iterrows():\n","        print(f\"{row['address']}\")\n","        print(f\"  Exact duplicate: {row['is_duplicate_exact']}\")\n","        print(f\"  Standard duplicate: {row['is_duplicate_standard']}\")\n","        if 'is_duplicate_fuzzy' in row:\n","            print(f\"  Fuzzy duplicate: {row['is_duplicate_fuzzy']}\")\n","\n","    # Test 9: Address validation\n","    print(\"\\n9. ADDRESS VALIDATION TEST\")\n","    print(\"-\" * 50)\n","    validation_tests = [\n","        \"Çankaya Mah. Atatürk Bulv. No:125 Ankara\",  # Valid\n","        \"İstanbul\",  # Too short\n","        \"-----\",  # Invalid\n","        \"12345\",  # Just numbers\n","        \"Ankara Çankaya\",  # Minimal but valid\n","        \"\"  # Empty\n","    ]\n","\n","    for addr in validation_tests:\n","        is_valid = processor.is_valid_turkish_address(processor.preprocess_address(addr))\n","        print(f\"Address: '{addr}' -> Valid: {is_valid}\")\n","\n","# Test 10: Generate report\n","print(\"\\n10. ADDRESS QUALITY REPORT\")\n","print(\"-\" * 50)\n","report = processor.generate_address_report(processed_df)\n","\n","# JSON yerine direkt yazdır\n","for key, value in report.items():\n","    if isinstance(value, dict):\n","        print(f\"{key}:\")\n","        for sub_key, sub_value in value.items():\n","            print(f\"  {sub_key}: {sub_value}\")\n","    else:\n","        print(f\"{key}: {value}\")\n","\n","    # Test 11: Number normalization edge cases\n","    print(\"\\n11. NUMBER NORMALIZATION EDGE CASES\")\n","    print(\"-\" * 50)\n","    number_tests = [\n","        \"No:25D:4\",\n","        \"No: 5\",\n","        \"No.25/A\",\n","        \"25/B\",\n","        \"D: 5\",\n","        \"Daire 5\",\n","        \"K: 2\",\n","        \"Kat: 2\",\n","        \"birinci kat\",\n","        \"ikinci sokak\",\n","        \"üçüncü cadde\"\n","    ]\n","\n","    for test in number_tests:\n","        normalized = processor.normalize_numbers(test.lower())\n","        print(f\"Input:  {test}\")\n","        print(f\"Output: {normalized}\")\n","\n","    # Test 12: Performance test\n","    print(\"\\n12. PERFORMANCE TEST\")\n","    print(\"-\" * 50)\n","    import time\n","\n","    # Generate test data\n","    large_test = test_addresses * 100  # 1300 addresses\n","\n","    start_time = time.time()\n","    large_df = pd.DataFrame({'address': large_test})\n","    processed_large = processor.preprocess_dataframe(large_df, extract_features=False, remove_duplicates=False)\n","    end_time = time.time()\n","\n","    processing_time = end_time - start_time\n","    addresses_per_second = len(large_test) / processing_time\n","\n","    print(f\"Processed {len(large_test)} addresses in {processing_time:.2f} seconds\")\n","    print(f\"Speed: {addresses_per_second:.0f} addresses/second\")\n","\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"ALL TESTS COMPLETED SUCCESSFULLY!\")\n","    print(\"=\" * 80)"]},{"cell_type":"code","source":["\"\"\"\n","Turkish Address Matching Model for Kaggle Competition\n","Using the comprehensive TurkishAddressProcessor\n","\"\"\"\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import time\n","from typing import Dict, List, Tuple\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class AddressMatchingModel:\n","    \"\"\"\n","    Production-ready model for Turkish address matching\n","    \"\"\"\n","\n","    def __init__(self, processor: TurkishAddressProcessor):\n","        self.processor = processor\n","\n","        # TF-IDF Vectorizers - multiple for better matching\n","        self.char_vectorizer = TfidfVectorizer(\n","            analyzer='char_wb',\n","            ngram_range=(3, 5),\n","            max_features=20000,\n","            lowercase=True,\n","            strip_accents='unicode'\n","        )\n","\n","        self.word_vectorizer = TfidfVectorizer(\n","            analyzer='word',\n","            ngram_range=(1, 3),\n","            max_features=15000,\n","            lowercase=True,\n","            strip_accents='unicode'\n","        )\n","\n","        # Store label information\n","        self.label_data = {}\n","        self.label_char_vectors = {}\n","        self.label_word_vectors = {}\n","\n","    def train(self, train_df: pd.DataFrame):\n","        \"\"\"\n","        Train the model on labeled address data\n","        \"\"\"\n","        print(\"=\" * 80)\n","        print(\"TRAINING ADDRESS MATCHING MODEL\")\n","        print(\"=\" * 80)\n","\n","        start_time = time.time()\n","\n","        # Preprocess training data\n","        print(\"\\n1. Preprocessing training data...\")\n","        train_processed = self.processor.preprocess_dataframe(\n","            train_df,\n","            address_col='address',\n","            extract_features=True,\n","            remove_duplicates=False\n","        )\n","\n","        # Get all unique labels\n","        unique_labels = train_df['label'].unique()\n","        print(f\"\\n2. Found {len(unique_labels)} unique locations\")\n","\n","        # Fit vectorizers on all processed addresses\n","        print(\"\\n3. Creating TF-IDF features...\")\n","        all_processed = train_processed['processed_address'].tolist()\n","        all_standardized = train_processed['standardized_address'].tolist()\n","\n","        # Fit both vectorizers\n","        print(\"   - Fitting character n-gram vectorizer...\")\n","        self.char_vectorizer.fit(all_processed + all_standardized)\n","\n","        print(\"   - Fitting word n-gram vectorizer...\")\n","        self.word_vectorizer.fit(all_processed + all_standardized)\n","\n","        # Process each label\n","        print(\"\\n4. Processing labels and creating vectors...\")\n","        processed_count = 0\n","\n","        for label in unique_labels:\n","            # Get all addresses for this label\n","            label_mask = train_df['label'] == label\n","            label_addresses = train_processed[label_mask]\n","\n","            if len(label_addresses) == 0:\n","                continue\n","\n","            # Store label data\n","            self.label_data[label] = {\n","                'addresses': label_addresses['processed_address'].tolist(),\n","                'standardized': label_addresses['standardized_address'].tolist(),\n","                'original': train_df[label_mask]['address'].tolist(),\n","                'count': len(label_addresses)\n","            }\n","\n","            # Create averaged vectors for this label\n","            # Char vectors\n","            char_vecs_processed = self.char_vectorizer.transform(\n","                label_addresses['processed_address']\n","            )\n","            char_vecs_standard = self.char_vectorizer.transform(\n","                label_addresses['standardized_address']\n","            )\n","\n","            # Combine processed and standardized\n","            all_char_vecs = np.vstack([\n","                char_vecs_processed.toarray(),\n","                char_vecs_standard.toarray()\n","            ])\n","            self.label_char_vectors[label] = np.mean(all_char_vecs, axis=0)\n","\n","            # Word vectors\n","            word_vecs_processed = self.word_vectorizer.transform(\n","                label_addresses['processed_address']\n","            )\n","            word_vecs_standard = self.word_vectorizer.transform(\n","                label_addresses['standardized_address']\n","            )\n","\n","            # Combine processed and standardized\n","            all_word_vecs = np.vstack([\n","                word_vecs_processed.toarray(),\n","                word_vecs_standard.toarray()\n","            ])\n","            self.label_word_vectors[label] = np.mean(all_word_vecs, axis=0)\n","\n","            processed_count += 1\n","            if processed_count % 1000 == 0:\n","                print(f\"   - Processed {processed_count}/{len(unique_labels)} labels...\")\n","\n","        training_time = time.time() - start_time\n","        print(f\"\\n✅ Training completed in {training_time:.2f} seconds\")\n","        print(f\"   - Total addresses: {len(train_df)}\")\n","        print(f\"   - Unique locations: {len(self.label_data)}\")\n","        print(f\"   - Avg addresses per location: {len(train_df)/len(self.label_data):.2f}\")\n","\n","    def predict_single(self, address: str) -> Tuple[int, float]:\n","        \"\"\"\n","        Predict label for a single address\n","\n","        Returns:\n","            Tuple[int, float]: (predicted_label, confidence_score)\n","        \"\"\"\n","        # Preprocess\n","        processed = self.processor.preprocess_address(address, standardize=False)\n","        standardized = self.processor.preprocess_address(address, standardize=True)\n","\n","        # If empty after preprocessing, return most common label\n","        if not processed:\n","            most_common = max(self.label_data.items(), key=lambda x: x[1]['count'])\n","            return most_common[0], 0.0\n","\n","        # Create vectors\n","        char_vec_proc = self.char_vectorizer.transform([processed])\n","        char_vec_std = self.char_vectorizer.transform([standardized])\n","        word_vec_proc = self.word_vectorizer.transform([processed])\n","        word_vec_std = self.word_vectorizer.transform([standardized])\n","\n","        best_label = None\n","        best_score = -1\n","\n","        # Compare with each label\n","        for label in self.label_data:\n","            # Character similarity\n","            char_sim_proc = cosine_similarity(\n","                char_vec_proc,\n","                self.label_char_vectors[label].reshape(1, -1)\n","            )[0, 0]\n","\n","            char_sim_std = cosine_similarity(\n","                char_vec_std,\n","                self.label_char_vectors[label].reshape(1, -1)\n","            )[0, 0]\n","\n","            # Word similarity\n","            word_sim_proc = cosine_similarity(\n","                word_vec_proc,\n","                self.label_word_vectors[label].reshape(1, -1)\n","            )[0, 0]\n","\n","            word_sim_std = cosine_similarity(\n","                word_vec_std,\n","                self.label_word_vectors[label].reshape(1, -1)\n","            )[0, 0]\n","\n","            # Combined score (weighted average)\n","            char_sim = max(char_sim_proc, char_sim_std)\n","            word_sim = max(word_sim_proc, word_sim_std)\n","            combined_score = 0.7 * char_sim + 0.3 * word_sim\n","\n","            if combined_score > best_score:\n","                best_score = combined_score\n","                best_label = label\n","\n","        return best_label, best_score\n","\n","    def predict(self, test_df: pd.DataFrame, batch_size: int = 100) -> pd.DataFrame:\n","        \"\"\"\n","        Predict labels for test dataset\n","        \"\"\"\n","        print(\"\\n\" + \"=\" * 80)\n","        print(\"PREDICTING TEST ADDRESSES\")\n","        print(\"=\" * 80)\n","\n","        start_time = time.time()\n","\n","        # Ensure test_df has id column\n","        if 'id' not in test_df.columns:\n","            test_df['id'] = range(len(test_df))\n","\n","        print(f\"\\nProcessing {len(test_df)} test addresses...\")\n","\n","        predictions = []\n","\n","        for idx, row in test_df.iterrows():\n","            label, confidence = self.predict_single(row['address'])\n","\n","            predictions.append({\n","                'id': row['id'],\n","                'label': label\n","            })\n","\n","            # Progress update\n","            if (idx + 1) % 1000 == 0:\n","                elapsed = time.time() - start_time\n","                speed = (idx + 1) / elapsed\n","                remaining = (len(test_df) - idx - 1) / speed\n","                print(f\"   Processed {idx + 1}/{len(test_df)} addresses \"\n","                      f\"({speed:.1f} addr/sec, ~{remaining:.0f}s remaining)\")\n","\n","        prediction_time = time.time() - start_time\n","        print(f\"\\n✅ Prediction completed in {prediction_time:.2f} seconds\")\n","        print(f\"   Speed: {len(test_df)/prediction_time:.1f} addresses/second\")\n","\n","        return pd.DataFrame(predictions)\n","\n","\n","def main():\n","    \"\"\"\n","    Main execution for Kaggle competition\n","    \"\"\"\n","    print(\"🏆 TURKISH ADDRESS MATCHING - KAGGLE COMPETITION\")\n","    print(\"=\" * 80)\n","\n","    # Initialize processor\n","    print(\"\\nInitializing address processor...\")\n","    processor = TurkishAddressProcessor()\n","\n","    # Load data\n","    print(\"\\nLoading data...\")\n","    train_df = pd.read_csv('train.csv')\n","    test_df = pd.read_csv('test.csv')\n","\n","    print(f\"✓ Train set loaded: {len(train_df)} addresses\")\n","    print(f\"✓ Test set loaded: {len(test_df)} addresses\")\n","\n","    # Data statistics\n","    print(\"\\nDataset Statistics:\")\n","    print(f\"- Unique labels in train: {train_df['label'].nunique()}\")\n","    print(f\"- Addresses per label: min={train_df['label'].value_counts().min()}, \"\n","          f\"max={train_df['label'].value_counts().max()}, \"\n","          f\"mean={train_df['label'].value_counts().mean():.2f}\")\n","\n","    # Show sample data\n","    print(\"\\nSample training data:\")\n","    for idx in np.random.choice(len(train_df), 3):\n","        print(f\"Label {train_df.iloc[idx]['label']}: {train_df.iloc[idx]['address']}\")\n","\n","    # Initialize and train model\n","    model = AddressMatchingModel(processor)\n","    model.train(train_df)\n","\n","    # Make predictions\n","    predictions = model.predict(test_df)\n","\n","    # Save submission\n","    submission_filename = 'submission.csv'\n","    predictions[['id', 'label']].to_csv(submission_filename, index=False)\n","    print(f\"\\n📁 Submission saved to: {submission_filename}\")\n","\n","    # Submission statistics\n","    print(\"\\nSubmission Statistics:\")\n","    print(f\"- Total predictions: {len(predictions)}\")\n","    print(f\"- Unique labels predicted: {predictions['label'].nunique()}\")\n","\n","    # Top predicted labels\n","    print(\"\\nTop 10 most predicted labels:\")\n","    top_labels = predictions['label'].value_counts().head(10)\n","    for label, count in top_labels.items():\n","        pct = count / len(predictions) * 100\n","        sample = train_df[train_df['label'] == label]['address'].iloc[0]\n","        print(f\"  Label {label}: {count} ({pct:.1f}%) - {sample[:60]}...\")\n","\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"✅ PIPELINE COMPLETED SUCCESSFULLY!\")\n","    print(\"=\" * 80)\n","    print(f\"\\n🎯 Next steps:\")\n","    print(f\"   1. Review the submission file: {submission_filename}\")\n","    print(f\"   2. Submit to Kaggle competition\")\n","    print(f\"   3. Check the leaderboard score\")\n","    print(f\"\\nGood luck! 🍀\")\n","\n","\n","if __name__ == \"__main__\":\n","    # Run the main pipeline\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKsUCxwj2L09","outputId":"112dae8b-6569-4007-ac2c-ab459fa9276e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🏆 TURKISH ADDRESS MATCHING - KAGGLE COMPETITION\n","================================================================================\n","\n","Initializing address processor...\n","\n","Loading data...\n","✓ Train set loaded: 848237 addresses\n","✓ Test set loaded: 217241 addresses\n","\n","Dataset Statistics:\n","- Unique labels in train: 10390\n","- Addresses per label: min=40, max=536, mean=81.64\n","\n","Sample training data:\n","Label 4990: Ferahlı Mh. Ferahlı, 3468. Sk. No:12, 35180 Buca Osb/Konak/İzmir, Türkiye No: 12 Daire: 2_3 Kat: 1_2 Konak/İzmir\n","Label 8546: KIRKAĞAÇ\n","Label 8392: Ragıpbey mah 17 sok 54/4 kardelen apt Akhisar Manisa Manisa Akhisar\n","================================================================================\n","TRAINING ADDRESS MATCHING MODEL\n","================================================================================\n","\n","1. Preprocessing training data...\n","Processing 848237 addresses...\n","Extracting address features...\n","  Processed 10000 addresses...\n","  Processed 20000 addresses...\n","  Processed 30000 addresses...\n","  Processed 40000 addresses...\n","  Processed 50000 addresses...\n","  Processed 60000 addresses...\n","  Processed 70000 addresses...\n","  Processed 80000 addresses...\n","  Processed 90000 addresses...\n","  Processed 100000 addresses...\n","  Processed 110000 addresses...\n","  Processed 120000 addresses...\n","  Processed 130000 addresses...\n","  Processed 140000 addresses...\n","  Processed 150000 addresses...\n","  Processed 160000 addresses...\n","  Processed 170000 addresses...\n","  Processed 180000 addresses...\n","  Processed 190000 addresses...\n","  Processed 200000 addresses...\n","  Processed 210000 addresses...\n","  Processed 220000 addresses...\n","  Processed 230000 addresses...\n","  Processed 240000 addresses...\n","  Processed 250000 addresses...\n","  Processed 260000 addresses...\n","  Processed 270000 addresses...\n","  Processed 280000 addresses...\n","  Processed 290000 addresses...\n","  Processed 300000 addresses...\n","  Processed 310000 addresses...\n","  Processed 320000 addresses...\n","  Processed 330000 addresses...\n","  Processed 340000 addresses...\n","  Processed 350000 addresses...\n","  Processed 360000 addresses...\n","  Processed 370000 addresses...\n","  Processed 380000 addresses...\n","  Processed 390000 addresses...\n","  Processed 400000 addresses...\n","  Processed 410000 addresses...\n","  Processed 420000 addresses...\n","  Processed 430000 addresses...\n","  Processed 440000 addresses...\n","  Processed 450000 addresses...\n","  Processed 460000 addresses...\n","  Processed 470000 addresses...\n","  Processed 480000 addresses...\n","  Processed 490000 addresses...\n","  Processed 500000 addresses...\n","  Processed 510000 addresses...\n","  Processed 520000 addresses...\n","  Processed 530000 addresses...\n","  Processed 540000 addresses...\n","  Processed 550000 addresses...\n","  Processed 560000 addresses...\n","  Processed 570000 addresses...\n","  Processed 580000 addresses...\n","  Processed 590000 addresses...\n","  Processed 600000 addresses...\n","  Processed 610000 addresses...\n","  Processed 620000 addresses...\n","  Processed 630000 addresses...\n","  Processed 640000 addresses...\n","  Processed 650000 addresses...\n","  Processed 660000 addresses...\n","  Processed 670000 addresses...\n","  Processed 680000 addresses...\n","  Processed 690000 addresses...\n","  Processed 700000 addresses...\n","  Processed 710000 addresses...\n","  Processed 720000 addresses...\n","  Processed 730000 addresses...\n","  Processed 740000 addresses...\n","  Processed 750000 addresses...\n","  Processed 760000 addresses...\n","  Processed 770000 addresses...\n","  Processed 780000 addresses...\n","  Processed 790000 addresses...\n","  Processed 800000 addresses...\n","  Processed 810000 addresses...\n","  Processed 820000 addresses...\n","  Processed 830000 addresses...\n","  Processed 840000 addresses...\n","\n","Preprocessing Statistics:\n","Total addresses: 848237\n","Valid addresses: 835602\n","\n","2. Found 10390 unique locations\n","\n","3. Creating TF-IDF features...\n","   - Fitting character n-gram vectorizer...\n","   - Fitting word n-gram vectorizer...\n","\n","4. Processing labels and creating vectors...\n","   - Processed 1000/10390 labels...\n","   - Processed 2000/10390 labels...\n","   - Processed 3000/10390 labels...\n","   - Processed 4000/10390 labels...\n","   - Processed 5000/10390 labels...\n","   - Processed 6000/10390 labels...\n","   - Processed 7000/10390 labels...\n","   - Processed 8000/10390 labels...\n","   - Processed 9000/10390 labels...\n","   - Processed 10000/10390 labels...\n","\n","✅ Training completed in 28406.46 seconds\n","   - Total addresses: 848237\n","   - Unique locations: 10390\n","   - Avg addresses per location: 81.64\n","\n","================================================================================\n","PREDICTING TEST ADDRESSES\n","================================================================================\n","\n","Processing 217241 test addresses...\n","   Processed 1000/217241 addresses (0.0 addr/sec, ~4335664s remaining)\n"]}]}]}