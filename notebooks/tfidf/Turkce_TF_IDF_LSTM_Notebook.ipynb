{"cells":[{"cell_type":"markdown","id":"550a8f62","metadata":{"id":"550a8f62"},"source":["# ğŸ“˜ TÃ¼rkÃ§e Metinlerle TF-IDF ve LSTM UygulamasÄ±\n","Bu notebook, metin temizleme, TF-IDF vektÃ¶rleÅŸtirme ve LSTM ile duygu analizi adÄ±mlarÄ±nÄ± TÃ¼rkÃ§e Ã¶rneklerle iÃ§erir."]},{"cell_type":"code","execution_count":1,"id":"41cec009","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41cec009","executionInfo":{"status":"ok","timestamp":1751956391467,"user_tz":-180,"elapsed":17176,"user":{"displayName":"Muhammet Fatih Ã‡etintas","userId":"02746250817952515216"}},"outputId":"873f961c-a876-4791-bf03-7363bf01cf1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install tensorflow scikit-learn nltk"]},{"cell_type":"code","execution_count":2,"id":"d5a136e6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5a136e6","executionInfo":{"status":"ok","timestamp":1751956461390,"user_tz":-180,"elapsed":7890,"user":{"displayName":"Muhammet Fatih Ã‡etintas","userId":"02746250817952515216"}},"outputId":"9fc5103f-7d9f-482c-c00e-f6a6bb2407d5"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["\n","import re\n","import numpy as np\n","import nltk\n","nltk.download('stopwords')\n","\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# TÃ¼rkÃ§e stopword'leri yÃ¼kle\n","stop_words = set(stopwords.words(\"turkish\"))\n","\n","# Metin temizleme fonksiyonu\n","def temizle_ve_tokenize(metin):\n","    temiz_metin = re.sub(r\"[^\\w\\s]\", \"\", metin)\n","    temiz_metin = temiz_metin.lower()\n","    kelimeler = temiz_metin.split()\n","    temiz_kelimeler = [k for k in kelimeler if k not in stop_words]\n","    return \" \".join(temiz_kelimeler)\n"]},{"cell_type":"code","execution_count":3,"id":"a5e86422","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a5e86422","executionInfo":{"status":"ok","timestamp":1751956487370,"user_tz":-180,"elapsed":21,"user":{"displayName":"Muhammet Fatih Ã‡etintas","userId":"02746250817952515216"}},"outputId":"bb0c2946-39bd-43b4-ee6c-572e5d87c083"},"outputs":[{"output_type":"stream","name":"stdout","text":["['film gÃ¼zeldi bayÄ±ldÄ±m', 'beÄŸenmedim sÄ±kÄ±cÄ±ydÄ±', 'oyunculuk harikaydÄ± senaryo zayÄ±ftÄ±', 'kadar kÃ¶tÃ¼ bir film izlememiÅŸtim', 'gÃ¶rsel efektler baÅŸarÄ±lÄ±ydÄ±']\n"]}],"source":["\n","yorumlar = [\n","    \"Film Ã§ok gÃ¼zeldi, bayÄ±ldÄ±m!\",\n","    \"HiÃ§ beÄŸenmedim, Ã§ok sÄ±kÄ±cÄ±ydÄ±.\",\n","    \"Oyunculuk harikaydÄ± ama senaryo zayÄ±ftÄ±.\",\n","    \"Bu kadar kÃ¶tÃ¼ bir film izlememiÅŸtim.\",\n","    \"GÃ¶rsel efektler baÅŸarÄ±lÄ±ydÄ±.\"\n","]\n","etiketler = np.array([1, 0, 1, 0, 1])\n","\n","temizlenmis_yorumlar = [temizle_ve_tokenize(y) for y in yorumlar]\n","print(temizlenmis_yorumlar)\n"]},{"cell_type":"code","execution_count":4,"id":"045774a6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"045774a6","executionInfo":{"status":"ok","timestamp":1751956501241,"user_tz":-180,"elapsed":12,"user":{"displayName":"Muhammet Fatih Ã‡etintas","userId":"02746250817952515216"}},"outputId":"de9615f5-ee19-42c2-89b4-c6019312a211"},"outputs":[{"output_type":"stream","name":"stdout","text":["TF-IDF Ã–zellikler: ['bayÄ±ldÄ±m' 'baÅŸarÄ±lÄ±ydÄ±' 'beÄŸenmedim' 'bir' 'efektler' 'film' 'gÃ¶rsel'\n"," 'gÃ¼zeldi' 'harikaydÄ±' 'izlememiÅŸtim' 'kadar' 'kÃ¶tÃ¼' 'oyunculuk' 'senaryo'\n"," 'sÄ±kÄ±cÄ±ydÄ±' 'zayÄ±ftÄ±']\n","TF-IDF VektÃ¶r Matrisi: [[0.61418897 0.         0.         0.         0.         0.49552379\n","  0.         0.61418897 0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.70710678 0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.70710678 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.5        0.         0.         0.\n","  0.5        0.5        0.         0.5       ]\n"," [0.         0.         0.         0.46369322 0.         0.37410477\n","  0.         0.         0.         0.46369322 0.46369322 0.46369322\n","  0.         0.         0.         0.        ]\n"," [0.         0.57735027 0.         0.         0.57735027 0.\n","  0.57735027 0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n"]}],"source":["\n","vektorizer = TfidfVectorizer()\n","X_tfidf = vektorizer.fit_transform(temizlenmis_yorumlar)\n","\n","print(\"TF-IDF Ã–zellikler:\", vektorizer.get_feature_names_out())\n","print(\"TF-IDF VektÃ¶r Matrisi:\", X_tfidf.toarray())\n"]},{"cell_type":"code","execution_count":5,"id":"6307e268","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6307e268","executionInfo":{"status":"ok","timestamp":1751956520315,"user_tz":-180,"elapsed":29,"user":{"displayName":"Muhammet Fatih Ã‡etintas","userId":"02746250817952515216"}},"outputId":"a406de4e-0c97-4595-ceb5-1e47bd40f5d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["SayÄ± dizileri: [[1, 2, 3], [4, 5], [6, 7, 8, 9], [10, 11, 12, 1, 13], [14, 15, 16]]\n","Pad edilmiÅŸ giriÅŸler: [[ 0  0  0  0  0  0  0  1  2  3]\n"," [ 0  0  0  0  0  0  0  0  4  5]\n"," [ 0  0  0  0  0  0  6  7  8  9]\n"," [ 0  0  0  0  0 10 11 12  1 13]\n"," [ 0  0  0  0  0  0  0 14 15 16]]\n"]}],"source":["\n","tokenizer = Tokenizer(num_words=1000)\n","tokenizer.fit_on_texts(temizlenmis_yorumlar)\n","sequences = tokenizer.texts_to_sequences(temizlenmis_yorumlar)\n","X_pad = pad_sequences(sequences, maxlen=10)\n","\n","print(\"SayÄ± dizileri:\", sequences)\n","print(\"Pad edilmiÅŸ giriÅŸler:\", X_pad)\n"]},{"cell_type":"code","execution_count":9,"id":"a7874308","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7874308","executionInfo":{"status":"ok","timestamp":1751956936594,"user_tz":-180,"elapsed":5247,"user":{"displayName":"Muhammet Fatih Ã‡etintas","userId":"02746250817952515216"}},"outputId":"87f44259-ffbe-4f01-cd47-0938183bd4e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.4000 - loss: 0.6938\n","Epoch 2/10\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.6000 - loss: 0.6909\n","Epoch 3/10\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8000 - loss: 0.6880\n","Epoch 4/10\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6000 - loss: 0.6852\n","Epoch 5/10\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6000 - loss: 0.6824\n","Epoch 6/10\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6000 - loss: 0.6795\n","Epoch 7/10\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6000 - loss: 0.6766\n","Epoch 8/10\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6000 - loss: 0.6737\n","Epoch 9/10\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6000 - loss: 0.6706\n","Epoch 10/10\n","\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.6000 - loss: 0.6675\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7c6a3947f910>"]},"metadata":{},"execution_count":9}],"source":["\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=1000, output_dim=32, input_length=10))\n","model.add(LSTM(32))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(X_pad, etiketler, epochs=10)\n"]},{"cell_type":"code","source":["import"],"metadata":{"id":"8jX1P2ipxXkw"},"id":"8jX1P2ipxXkw","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}